module LLaMACpp
  VERSION: String
  LLAMA_CPP_VERSION: String
  LLAMA_FILE_VERSION: String
  LLAMA_FILE_MAGIC: String
  LLAMA_FILE_MAGIC_UNVERSIONED: String
  LLAMA_DEFALUT_SEED: String

  LLAMA_MAX_DEVICES: Integer

  LLAMA_FTYPE_ALL_F32: Integer
  LLAMA_FTYPE_MOSTLY_F16: Integer
  LLAMA_FTYPE_MOSTLY_Q4_0: Integer
  LLAMA_FTYPE_MOSTLY_Q4_1: Integer
  LLAMA_FTYPE_MOSTLY_Q4_1_SOME_F16: Integer
  LLAMA_FTYPE_MOSTLY_Q8_0: Integer
  LLAMA_FTYPE_MOSTLY_Q5_0: Integer
  LLAMA_FTYPE_MOSTLY_Q5_1: Integer
  LLAMA_FTYPE_MOSTLY_Q2_K: Integer
  LLAMA_FTYPE_MOSTLY_Q3_K_S: Integer
  LLAMA_FTYPE_MOSTLY_Q3_K_M: Integer
  LLAMA_FTYPE_MOSTLY_Q3_K_L: Integer
  LLAMA_FTYPE_MOSTLY_Q4_K_S: Integer
  LLAMA_FTYPE_MOSTLY_Q4_K_M: Integer
  LLAMA_FTYPE_MOSTLY_Q5_K_S: Integer
  LLAMA_FTYPE_MOSTLY_Q5_K_M: Integer
  LLAMA_FTYPE_MOSTLY_Q6_K: Integer

  LLAMA_GRETYPE_END: Integer
  LLAMA_GRETYPE_ALT: Integer
  LLAMA_GRETYPE_RULE_REF: Integer
  LLAMA_GRETYPE_CHAR: Integer
  LLAMA_GRETYPE_CHAR_NOT: Integer
  LLAMA_GRETYPE_CHAR_RNG_UPPER: Integer
  LLAMA_GRETYPE_CHAR_ALT: Integer

  def self?.backend_init: (?numa: bool) -> void
  def self?.backend_free: () -> void
  def self?.model_quantize: (input_path: String, output_path: String, params: ModelQuantizeParams) -> void
  def self?.generate: (::LLaMACpp::Context, String,
    ?n_predict: Integer, ?n_threads: Integer, ?n_keep: Integer, ?n_batch: Integer,
    ?repeat_last_n: Integer, ?repeat_penalty: Float, ?frequency: Float, ?presence: Float,
    ?top_k: Integer, ?top_p: Float, ?tfs_z: Float, ?typical_p: Float, ?temperature: Float) -> String
  def self?.print_system_info: () -> void
  def self?.token_bos: () -> Integer
  def self?.token_eos: () -> Integer
  def self?.token_nl: () -> Integer
  def self?.mmap_supported?: () -> bool
  def self?.mlock_supported?: () -> bool
  def self?.max_devices: () -> Integer

  class TokenData
    public

    def initialize: (id: Integer, logit: Float, p: Float) -> void
    def id: () -> Integer
    def id=: (Integer) -> Integer
    def logit: () -> Float
    def logit=: (Float) -> Float
    def p: () -> Float
    def p=: (Float) -> Float
  end

  class TokenDataArray
    public

    def initialize: (Array[::LLaMACpp::TokenData], ?sorted: bool) -> void
    def size: () -> Integer
    def sorted: () -> bool
  end

  class Model
    public

    def initialize: (model_path: String, params: ::LLaMACpp::ContextParams) -> void
                  | () -> void
    def empty?: () -> bool
    def free: () -> void
    def load: (model_path: String, params: ::LLaMACpp::ContextParams) -> void
    def apply_lora_from_file: (lora_path: String, ?base_model_path: String, ?n_threads: Integer) -> void
    def n_vocab: () -> Integer
    def n_ctx: () -> Integer
    def n_embd: () -> Integer
    def vocab: (capacity: Integer) -> [Array[String], Array[Float]]
    def token_to_str: (Integer) -> String
    def tokenize: (text: String, ?n_max_tokens: Integer, ?add_bos: bool) -> Array[Integer]
  end

  class Timings
    public

    def t_start_ms: () -> Float
    def t_end_ms: () -> Float
    def t_load_ms: () -> Float
    def t_sample_ms: () -> Float
    def t_p_eval_ms: () -> Float
    def t_eval_ms: () -> Float
    def n_sample: () -> Integer
    def n_p_eval: () -> Integer
    def n_eval: () -> Integer
  end

  class Context
    public

    def initialize: (model: ::LLaMACpp::Model) -> void
    def embeddings: () -> Array[Float]
    def eval: (tokens: Array[Integer], n_past: Integer, ?n_tokens: Integer, ?n_threads: Integer) -> void
    def eval_embd: (tokens: Array[Float], n_past: Integer, ?n_tokens: Integer, ?n_threads: Integer) -> void
    def eval_export: (String) -> bool
    def logits: () -> Array[Float]
    def n_ctx: () -> Integer
    def n_embd: () -> Integer
    def n_vocab: () -> Integer
    def vocab: (capacity: Integer) -> [Array[String], Array[Float]]
    def timings: () -> ::LLaMACpp::Timings
    def print_timings: () -> void
    def reset_timings: () -> void
    def token_to_str: (Integer) -> String
    def tokenize: (text: String, ?n_max_tokens: Integer, ?add_bos: bool) -> Array[Integer]
    def kv_cache_token_count: () -> Integer
    def set_rng_seed: (Integer) -> void
    def load_session_file: (session_path: String) -> void
    def save_session_file: (session_path: String, session_tokens: Array[Integer]) -> void
    def sample_repetition_penalty: (::LLaMACpp::TokenDataArray, Array[Integer], penalty: Float) -> void
    def sample_frequency_and_presence_penalties: (::LLaMACpp::TokenDataArray, Array[Integer], frequency: Float, presence: Float) -> void
    def sample_classifier_free_guidance: (::LLaMACpp::TokenDataArray, guidance: ::LLaMACpp::Context, scale: Float) -> void
    def sample_softmax: (::LLaMACpp::TokenDataArray) -> void
    def sample_top_k: (::LLaMACpp::TokenDataArray, k: Integer, ?min_keep: Integer) -> void
    def sample_top_p: (::LLaMACpp::TokenDataArray, prob: Float, ?min_keep: Integer) -> void
    def sample_tail_free: (::LLaMACpp::TokenDataArray, z: Float, ?min_keep: Integer) -> void
    def sample_typical: (::LLaMACpp::TokenDataArray, prob: Float, ?min_keep: Integer) -> void
    def sample_temperature: (::LLaMACpp::TokenDataArray, temperature: Float) -> void
    def sample_token_mirostat: (::LLaMACpp::TokenDataArray, tau: Float, eta: Float, m: Integer, mu: Float) -> [Integer, Float]
    def sample_token_mirostat_v2: (::LLaMACpp::TokenDataArray, tau: Float, eta: Float, mu: Float) -> [Integer, Float]
    def sample_token_greedy: (::LLaMACpp::TokenDataArray) -> Integer
    def sample_token: (::LLaMACpp::TokenDataArray) -> Integer
    def sample_grammar: (::LLaMACpp::TokenDataArray, grammar: ::LLaMACpp::Grammar) -> void
    def grammar_accept_token: (grammar: ::LLaMACpp::Grammar, token: Integer) -> void
  end

  class ContextParams
    public

    def embedding: () -> bool
    def embedding=: (bool) -> bool
    def f16_kv: () -> bool
    def f16_kv=: (bool) -> bool
    def logits_all: () -> bool
    def logits_all=: (bool) -> bool
    def n_ctx: () -> Integer
    def n_ctx=: (Integer) -> Integer
    def n_batch: () -> Integer
    def n_batch=: (Integer) -> Integer
    def n_gpu_layers: () -> Integer
    def n_gpu_layers=: (Integer) -> Integer
    def main_gpu: () -> Integer
    def main_gpu=: (Integer) -> Integer
    def tensor_split: () -> Array[Float]
    def rope_freq_base=: (Float) -> Float
    def rope_freq_base: () -> Float
    def rope_freq_scale=: (Float) -> Float
    def rope_freq_scale: () -> Float
    def low_vram: () -> bool
    def low_vram=: (bool) -> bool
    def seed: () -> Integer
    def seed=: (Integer) -> Integer
    def use_mlock: () -> bool
    def use_mlock=: (bool) -> bool
    def use_mmap: () -> bool
    def use_mmap=: (bool) -> bool
    def vocab_only: () -> bool
    def vocab_only=: (bool) -> bool
  end

  class ModelQuantizeParams
    public

    def n_thread: () -> Integer
    def n_thread=: (Integer) -> Integer
    def ftype: () -> Integer
    def ftype=: (Integer) -> Integer
    def allow_quantization: () -> bool
    def allow_quantization=: (bool) -> bool
    def quantize_output_tensor: () -> bool
    def quantize_output_tensor=: (bool) -> bool
  end

  class Params = ContextParams

  class GrammarElement
    public

    def initialize: (?type: Integer, ?value: Integer) -> void
    def type: () -> Integer
    def type=: (Integer) -> Integer
    def value: () -> Integer
    def value=: (Integer) -> Integer
  end

  class Grammar
    def initialize: (rules: Array[Array[LLaMACpp::GrammarElement]], start_rule_index: Integer) -> void
  end
end
